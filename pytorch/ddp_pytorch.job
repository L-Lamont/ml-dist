#!/bin/bash

#SBATCH --job-name=pytorch-example
#SBATCH --partition=example-partition
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --constraint=example-constraint

msg() { printf "$*\n" >&2; }
die() { msg "!!! $*"; exit 1; }
log() { msg "### $*"; }

# Change the specific versions being loaded
module purge
module load slurm
module load openmpi
module load cuda
module load nccl
module load python
module load apptainer

# Set proxy variables (if necessary)
export http_proxy="http://example_proxy.com"
export https_proxy="http://example_proxy.com"

# USE_CONTAINER=1 will launch using the container otherwise it will use the venv
USE_CONTAINER=0

# Update 
TEST_NAME="${SLURM_JOB_NAME}"
TRAIN_SCRIPT_NAME="ddp_training.py" # Set which script to use
FRAMEWORK="pytorch"
CONTAINER_NAME="pytorch_latest.sif"
GPUS_PER_NODE=1 # Set to number of gpus to be used per node

# Update the path 
ML_DIST_PATH="/path/to/ml-dist"
DATA="${ML_DIST_PATH}/${FRAMEWORK}/data"
TRAIN_SCRIPT="${ML_DIST_PATH}/${FRAMEWORK}/${TRAIN_SCRIPT_NAME}"
OUTPUT="${ML_DIST_PATH}/$FRAMEWORK/output/${TEST_NAME}-$(date +%F.%T)"
VENV="${ML_DIST_PATH}/${FRAMEWORK}/venv"
CONTAINER="${ML_DIST_PATH}/${FRAMEWORK}/${CONTAINER_NAME}"

log "TEST_NAME: ${TEST_NAME}"
log "FRAMEWORK: ${FRAMEWORK}"
log "TRAIN_SCRIPT: ${TRAIN_SCRIPT}"
log "OUTPUT: ${OUTPUT}"
log "DATA: ${DATA}"
log "VENV: ${VENV}"
log "CONTAINER: ${CONTAINER}"

export TMPDIR="${TMPDIR_SHM}" # Stops pytorch errors from being on a network file system
export MASTER_ADDR="$(scontrol show hostname "${SLURM_JOB_NODELIST}" | head -n 1):29401"

# Basic Checks
[[ -f "${TRAIN_SCRIPT}" ]] || die "Can't find ${TRAIN_SCRIPT}"

mkdir "${OUTPUT}"
[[ -d "${OUTPUT}" ]] || die "OUTPUT directory not created"

trainArgs="
    --data-dir=${DATA}
    --output-dir=${OUTPUT}
"

torchrunArgs="
    --nproc_per_node ${GPUS_PER_NODE}
    --nnodes ${SLURM_NNODES}
    --rdzv_endpoint ${MASTER_ADDR}
    --rdzv_backend c10d
"

mpiArgs="
    --np ${SLURM_JOB_NUM_NODES}
    --bind-to none
    -map-by slot
    -x NCCL_DEBUG=INFO
    -x NCCL_IB_GID_INDEX=3
    -x LD_LIBRARY_PATH
    -x PATH
"


if [[ "${USE_CONTAINER}" == 0 ]]; then
    log "Using venv: ${VENV}"
    [[ -f "${VENV}/bin/activate" ]] || die "Can't find activate in ${VENV}"
    source "${VENV}/bin/activate"
    [[ -z "${VIRTUAL_ENV}" ]] && die "Can't activate ${VENV}"

    time mpirun ${mpiArgs} torchrun ${torchrunArgs} ${TRAIN_SCRIPT} ${trainArgs}
else
    log "Using container: ${CONTAINER}"
    apptainerArgs="
        --nv
        -B ${ML_DIST_PATH}:${ML_DIST_PATH}
        ${CONTAINER}
        torchrun ${torchrunArgs} ${TRAIN_SCRIPT} ${trainArgs}
    "
    time mpirun ${mpiArgs} apptainer run ${apptainerArgs}
fi
